{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f1f48be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "232e69ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files\n",
    "train_filename = \"Constraint_English_Train.xlsx\"\n",
    "val_filename = \"Constraint_English_Val.xlsx\"\n",
    "test_filename = \"Constraint_English_Test.xlsx\"\n",
    "\n",
    "train_data = pd.read_excel(train_filename)\n",
    "validation_data = pd.read_excel(val_filename)\n",
    "test_data = pd.read_excel(test_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ab21730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the training data:  (6420, 3)\n",
      "Size of the validation data:  (2140, 3)\n",
      "Size of the test data:  (2140, 3)\n"
     ]
    }
   ],
   "source": [
    "#check size\n",
    "print(\"Size of the training data: \", train_data.shape)\n",
    "print(\"Size of the validation data: \", validation_data.shape)\n",
    "print(\"Size of the test data: \", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc078b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label transform\n",
    "train_data['training_label']= train_data.label.replace({'real':0,'fake':1})\n",
    "validation_data['validation_label']= validation_data.label.replace({'real':0,'fake':1})\n",
    "test_data['validation_label']= test_data.label.replace({'real':0,'fake':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91c052ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "punctuations = '''’'!()-[]{};:'\"\\,<>./?@#$%^&*_~�'''\n",
    "\n",
    "def remove_punctuation_url(d):\n",
    "    d = d.lower()\n",
    "    #remove url\n",
    "    d = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', d, flags=re.MULTILINE)\n",
    "    review = d.replace('\\n', '')\n",
    "    no_punct = \"\"\n",
    "    #remove punc\n",
    "    for char in review:\n",
    "        if char not in punctuations:\n",
    "            no_punct = no_punct + char\n",
    "    return no_punct\n",
    "\n",
    "def remove_stopwords(d):\n",
    "    text_tokens = word_tokenize(d.lower())\n",
    "    tokens_without_sw = [word for word in text_tokens if not word in stopwords.words('english')]\n",
    "    ls = \"\"\n",
    "    for w in tokens_without_sw:\n",
    "        ls = ls +\" \"+w.lower()\n",
    "    return ls\n",
    "\n",
    "train_data['cleaned'] = train_data['tweet'].apply(remove_punctuation_url)\n",
    "validation_data['cleaned'] = validation_data['tweet'].apply(remove_punctuation_url)\n",
    "test_data['cleaned'] = test_data['tweet'].apply(remove_punctuation_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5673473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrices(pred,true):\n",
    "    print(confusion_matrix(true,pred))\n",
    "    print(classification_report(true,pred,))\n",
    "    print(\"Accuracy : \",accuracy_score(pred,true))\n",
    "    print(\"Precison : \",precision_score(pred,true, average = 'weighted'))\n",
    "    print(\"Recall : \",recall_score(pred,true,  average = 'weighted'))\n",
    "    print(\"F1 : \",f1_score(pred,true,  average = 'weighted'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7486ec07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM(Linear)\n",
      "val:\n",
      "[[ 936   84]\n",
      " [  48 1072]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.95      0.92      0.93      1020\n",
      "        real       0.93      0.96      0.94      1120\n",
      "\n",
      "    accuracy                           0.94      2140\n",
      "   macro avg       0.94      0.94      0.94      2140\n",
      "weighted avg       0.94      0.94      0.94      2140\n",
      "\n",
      "Accuracy :  0.9383177570093458\n",
      "Precison :  0.9389821723081755\n",
      "Recall :  0.9383177570093458\n",
      "F1 :  0.9383839682296299\n",
      "[[ 942   78]\n",
      " [  51 1069]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.95      0.92      0.94      1020\n",
      "        real       0.93      0.95      0.94      1120\n",
      "\n",
      "    accuracy                           0.94      2140\n",
      "   macro avg       0.94      0.94      0.94      2140\n",
      "weighted avg       0.94      0.94      0.94      2140\n",
      "\n",
      "Accuracy :  0.9397196261682244\n",
      "Precison :  0.9401099259797377\n",
      "Recall :  0.9397196261682244\n",
      "F1 :  0.9397649209453509\n"
     ]
    }
   ],
   "source": [
    "#########LinearSVM#########\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('bow', CountVectorizer()),  \n",
    "        ('tfidf', TfidfTransformer()),  \n",
    "        ('c', LinearSVC())\n",
    "    ])\n",
    "fit = pipeline.fit(train_data['tweet'],train_data['label'])\n",
    "print('SVM(Linear)')\n",
    "print ('val:')\n",
    "pred=pipeline.predict(validation_data['tweet'])\n",
    "print_metrices(pred,validation_data['label'])\n",
    "pred=pipeline.predict(test_data['tweet'])\n",
    "print_metrices(pred,test_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57215daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM(poly3)\n",
      "val:\n",
      "[[ 940   80]\n",
      " [  42 1078]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.96      0.92      0.94      1020\n",
      "        real       0.93      0.96      0.95      1120\n",
      "\n",
      "    accuracy                           0.94      2140\n",
      "   macro avg       0.94      0.94      0.94      2140\n",
      "weighted avg       0.94      0.94      0.94      2140\n",
      "\n",
      "Accuracy :  0.9429906542056075\n",
      "Precison :  0.9437174729704966\n",
      "Recall :  0.9429906542056075\n",
      "F1 :  0.943056206960435\n",
      "[[ 945   75]\n",
      " [  51 1069]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.95      0.93      0.94      1020\n",
      "        real       0.93      0.95      0.94      1120\n",
      "\n",
      "    accuracy                           0.94      2140\n",
      "   macro avg       0.94      0.94      0.94      2140\n",
      "weighted avg       0.94      0.94      0.94      2140\n",
      "\n",
      "Accuracy :  0.9411214953271028\n",
      "Precison :  0.941435443336213\n",
      "Recall :  0.9411214953271028\n",
      "F1 :  0.9411598857369308\n"
     ]
    }
   ],
   "source": [
    "#########SVM(poly3)#########\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('bow', CountVectorizer()),  \n",
    "        ('tfidf', TfidfTransformer()),  \n",
    "        (\"svm_clf\", SVC(kernel=\"poly\", degree=3, coef0=2, C=10))\n",
    "    ])\n",
    "fit = pipeline.fit(train_data['tweet'],train_data['label'])\n",
    "print('SVM(poly3)')\n",
    "print ('val:')\n",
    "pred=pipeline.predict(validation_data['tweet'])\n",
    "print_metrices(pred,validation_data['label'])\n",
    "pred=pipeline.predict(test_data['tweet'])\n",
    "print_metrices(pred,test_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5cb91c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM(rbf)\n",
      "val:\n",
      "[[ 940   80]\n",
      " [  48 1072]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.95      0.92      0.94      1020\n",
      "        real       0.93      0.96      0.94      1120\n",
      "\n",
      "    accuracy                           0.94      2140\n",
      "   macro avg       0.94      0.94      0.94      2140\n",
      "weighted avg       0.94      0.94      0.94      2140\n",
      "\n",
      "Accuracy :  0.9401869158878504\n",
      "Precison :  0.9407188669860467\n",
      "Recall :  0.9401869158878504\n",
      "F1 :  0.9402422952654304\n",
      "[[ 947   73]\n",
      " [  50 1070]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.95      0.93      0.94      1020\n",
      "        real       0.94      0.96      0.95      1120\n",
      "\n",
      "    accuracy                           0.94      2140\n",
      "   macro avg       0.94      0.94      0.94      2140\n",
      "weighted avg       0.94      0.94      0.94      2140\n",
      "\n",
      "Accuracy :  0.9425233644859813\n",
      "Precison :  0.9428127536061154\n",
      "Recall :  0.9425233644859813\n",
      "F1 :  0.9425589877601502\n"
     ]
    }
   ],
   "source": [
    "#########SVM(rbf)#########\n",
    "pipeline = Pipeline([\n",
    "        ('bow', CountVectorizer()),  \n",
    "        ('tfidf', TfidfTransformer()),  \n",
    "        (\"svm_clf\", SVC(kernel=\"rbf\", gamma=1, C=10))\n",
    "    ])\n",
    "fit = pipeline.fit(train_data['tweet'],train_data['label'])\n",
    "print('SVM(rbf)')\n",
    "print ('val:')\n",
    "pred=pipeline.predict(validation_data['tweet'])\n",
    "print_metrices(pred,validation_data['label'])\n",
    "pred=pipeline.predict(test_data['tweet'])\n",
    "print_metrices(pred,test_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e0517e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "val:\n",
      "[[887 133]\n",
      " [131 989]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.87      0.87      0.87      1020\n",
      "        real       0.88      0.88      0.88      1120\n",
      "\n",
      "    accuracy                           0.88      2140\n",
      "   macro avg       0.88      0.88      0.88      2140\n",
      "weighted avg       0.88      0.88      0.88      2140\n",
      "\n",
      "Accuracy :  0.8766355140186916\n",
      "Precison :  0.8766480634309799\n",
      "Recall :  0.8766355140186916\n",
      "F1 :  0.876641021848765\n",
      "[[876 144]\n",
      " [128 992]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.87      0.86      0.87      1020\n",
      "        real       0.87      0.89      0.88      1120\n",
      "\n",
      "    accuracy                           0.87      2140\n",
      "   macro avg       0.87      0.87      0.87      2140\n",
      "weighted avg       0.87      0.87      0.87      2140\n",
      "\n",
      "Accuracy :  0.8728971962616823\n",
      "Precison :  0.8730982486452525\n",
      "Recall :  0.8728971962616823\n",
      "F1 :  0.8729488597229612\n"
     ]
    }
   ],
   "source": [
    "#########Decision Tree#########\n",
    "pipeline = Pipeline([\n",
    "        ('bow', CountVectorizer()),  \n",
    "        ('tfidf', TfidfTransformer()),  \n",
    "        ('c', tree.DecisionTreeClassifier())\n",
    "    ])\n",
    "fit = pipeline.fit(train_data['tweet'],train_data['label'])\n",
    "print('Decision Tree')\n",
    "print ('val:')\n",
    "pred=pipeline.predict(validation_data['tweet'])\n",
    "print_metrices(pred,validation_data['label'])\n",
    "pred=pipeline.predict(test_data['tweet'])\n",
    "print_metrices(pred,test_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea0d1fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "val:\n",
      "[[ 925   95]\n",
      " [  62 1058]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.94      0.91      0.92      1020\n",
      "        real       0.92      0.94      0.93      1120\n",
      "\n",
      "    accuracy                           0.93      2140\n",
      "   macro avg       0.93      0.93      0.93      2140\n",
      "weighted avg       0.93      0.93      0.93      2140\n",
      "\n",
      "Accuracy :  0.9266355140186916\n",
      "Precison :  0.9272181045315322\n",
      "Recall :  0.9266355140186916\n",
      "F1 :  0.9267060977562901\n",
      "[[ 928   92]\n",
      " [  63 1057]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.94      0.91      0.92      1020\n",
      "        real       0.92      0.94      0.93      1120\n",
      "\n",
      "    accuracy                           0.93      2140\n",
      "   macro avg       0.93      0.93      0.93      2140\n",
      "weighted avg       0.93      0.93      0.93      2140\n",
      "\n",
      "Accuracy :  0.927570093457944\n",
      "Precison :  0.9280301104086495\n",
      "Recall :  0.927570093457944\n",
      "F1 :  0.9276294760384962\n"
     ]
    }
   ],
   "source": [
    "#########Logistic Regression#########\n",
    "pipeline = Pipeline([\n",
    "        ('bow', CountVectorizer()),  \n",
    "        ('tfidf', TfidfTransformer()),  \n",
    "        ('c', LogisticRegression())\n",
    "    ])\n",
    "fit = pipeline.fit(train_data['tweet'],train_data['label'])\n",
    "print('Logistic Regression')\n",
    "print ('val:')\n",
    "pred=pipeline.predict(validation_data['tweet'])\n",
    "print_metrices(pred,validation_data['label'])\n",
    "pred=pipeline.predict(test_data['tweet'])\n",
    "print_metrices(pred,test_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e172d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1ca268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb92bbc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8016bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306b8a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a34c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9091002a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
